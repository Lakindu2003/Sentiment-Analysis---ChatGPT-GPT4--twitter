##LIBRARIES
```{r}
library(dplyr)
library(tidyr)
library(tidytext)
library(textdata)
library(ggplot2)
library(ggthemes)
library(scales)
data("stop_words")
```

##DATASETS
```{r}
tweets <- read.csv(file = "tweets.csv")
tweets <- tweets |> select(text)
```

#EXTRACTING TWEETS
```{r}
extract_words <- function(string) {
  words <- tolower(gsub("[^[:alpha:]]+", " ", string))
  words <- unlist(strsplit(words, split = "\\s+"))
  words <- words[words != ""]
  return(words)
}

all_words <- unlist(lapply(tweets$text, extract_words))
```

##SENTIMENTAL ANALYSIS OF TWEETS NRC
```{r}
sentiments_nrc <- get_sentiments(lexicon = "nrc")
words_nrc <- data.frame(word = all_words) |>
  unnest_tokens(output = word, input = word) |>
  anti_join(y = stop_words, by = "word") |>
  inner_join(y = sentiments_nrc, by = "word")
head(words_nrc)
```

```{r}
top_n_nrc <- words_nrc |> 
  group_by(sentiment) |>
  count(word, sentiment) |>
  top_n(1) |>
  slice_max(n = 1, order_by = n) |>
  ungroup() |>
  select(sentiment, word)
  
words_nrc |> count(sentiment) |>
  full_join(top_n_nrc)
top_n_nrc
```

```{r}
words_nrc |> count(sentiment) |>
  ggplot(aes(x = reorder(sentiment, -n), y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  scale_y_continuous(labels = number_format()) +
  labs(y = "Number of Words",
       x = "Sentiments",
       title = "Most common sentiments in tweets about GPTs") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_text(aes(label = n, vjust = -0.3))
```


##SENTIMENTAL ANALYSIS OF TWEETS AFINN
```{r}
sentiments_afinn <- get_sentiments(lexicon = "afinn")
words_afinn <- data.frame(word = all_words) |>
  unnest_tokens(output = word, input = word) |>
  anti_join(y = stop_words, by = "word") |>
  inner_join(y = sentiments_afinn, by = "word") |>
  count(value, word) |>
  arrange(desc(n)) |>
  group_by(value) |>
  top_n(n = 1, wt = n) |>
  arrange(value)
head(words_afinn)
```

```{r}
words_afinn |> ggplot(aes(x = value,y=n, fill = word)) +
  geom_col() +
  labs(x="Sentiment Value", y="Word Count",title = "Most common word for each Sentiment Value") +
  scale_x_continuous(breaks=seq(-5,5,1)) + 
  geom_text(aes(label = n, vjust = -0.3)) 
```
